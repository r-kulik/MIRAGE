\chapter{Literature Review}
\label{chap:lr}
\chaptermark{Second Chapter Heading}


\section[Foundations of Retrieval-Augmented Generation]{\texorpdfstring{Foundations of \\ Retrieval-Augmented Generation}{Foundations of Retrieval-Augmented Generation}}
\subsection{Core architecture of RAG-systems}
As it was said in Chapter 1, in 2020 a Retrieval-Augmented approach was presented by Lewis et al. in \cite{lewisRetrievalAugmentedGenerationKnowledgeIntensive2020}.
The idea of RAG is novel and simple at the same time: it combines the power of LLMs with the reliability of information retrieval systems.
Its architecture consists of two main componentents: a retriever and a generator.
The retriever is responsible for searching and retrieving relevant documents from a large corpus, while the generator uses these documents to produce coherent and contextually relevant responses.
The retriever can be based on various techniques, such as dense retrieval, sparse retrieval, or a combination of both.
The generator is typically a pre-trained language model, such as BART or T5, which is fine-tuned on the task of generating text based on the retrieved documents.

