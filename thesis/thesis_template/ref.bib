@article{automation_in_legal_1958,
  author = {D. L. Mehl},
  title = {AUTOMATION IN THE LEGAL WORLD},
  journal = {Mechanisation of Thought Processes},
  year = {1958}
}

@inproceedings{weaverTranslation1952,
  title = {Translation},
  booktitle = {Proceedings of the {{Conference}} on {{Mechanical Translation}}},
  author = {Weaver, Warren},
  year = {1952},
  address = {Massachusetts Institute of Technology},
  urldate = {2025-03-30},
  file = {C:\Users\Bulkin\Zotero\storage\DN7I9A2I\Weaver - 1952 - Translation.pdf}
}

@article{brownStatisticalApproachMachine1990,
  title = {A {{Statistical Approach}} to {{Machine Translation}}},
  author = {Brown, Peter F. and Cocke, John and Della Pietra, Stephen A. and Della Pietra, Vincent J. and Jelinek, Fredrick and Lafferty, John D. and Mercer, Robert L. and Roossin, Paul S.},
  year = {1990},
  journal = {Computational Linguistics},
  volume = {16},
  number = {2},
  pages = {79--85},
  urldate = {2025-03-30},
  file = {C:\Users\Bulkin\Zotero\storage\LBZXV7DH\Brown и др. - 1990 - A Statistical Approach to Machine Translation.pdf}
}

@article{merigouxCatalaProgrammingLanguage2021,
  title = {Catala: {{A Programming Language}} for the {{Law}}},
  shorttitle = {Catala},
  author = {Merigoux, Denis and Chataing, Nicolas and Protzenko, Jonathan},
  year = {2021},
  journal = {Proceedings of the ACM on Programming Languages},
  volume = {5},
  number = {ICFP},
  pages = {77:1},
  doi = {10.1145/3473582},
  urldate = {2025-03-30},
  abstract = {Law at large underpins modern society, codifying and governing many aspects of citizens' daily lives. Oftentimes, law is subject to interpretation, debate and challenges throughout various courts and jurisdictions. But in some other areas, law leaves little room for interpretation, and essentially aims to rigorously describe a computation, a decision procedure or, simply said, an algorithm. Unfortunately, prose remains a woefully inadequate tool for the job. The lack of formalism leaves room for ambiguities; the structure of legal statutes, with many paragraphs and subsections spread across multiple pages, makes it hard to compute the intended outcome of the algorithm underlying a given text; and, as with any other piece of poorly-specified critical software, the use of informal, natural language leaves corner cases unaddressed. We introduce Catala, a new programming language that we specifically designed to allow a straightforward and systematic translation of statutory law into an executable implementation. Catala aims to bring together lawyers and programmers through a shared medium, which together they can understand, edit and evolve, bridging a gap that too often results in dramatically incorrect implementations of the law. We have implemented a compiler for Catala, and have proven the correctness of its core compilation steps using the F {$\star$} proof assistant. We evaluate Catala on several legal texts that are algorithms in disguise, notably section 121 of the US federal income tax and the byzantine French family benefits; in doing so, we uncover a bug in the official implementation of the French benefits. We observe as a consequence of the formalization process that using Catala enables rich interactions between lawyers and programmers, leading to a greater understanding of the original legislative intent, while producing a correct-by-construction executable specification reusable by the greater software ecosystem. Doing so, Catala increases trust in legal institutions, and mitigates the risk of societal damage due to incorrect implementations of the law.},
  langid = {english},
  file = {C:\Users\Bulkin\Zotero\storage\BXJLTKJH\Merigoux и др. - 2021 - Catala A Programming Language for the Law.pdf}
}


@article{risslandAILawFruitful2003,
  title = {{{AI}} and {{Law}}: {{A}} Fruitful Synergy},
  shorttitle = {{{AI}} and {{Law}}},
  author = {Rissland, Edwina L. and Ashley, Kevin D. and Loui, R.P.},
  year = {2003},
  month = nov,
  journal = {Artificial Intelligence},
  volume = {150},
  number = {1-2},
  pages = {1--15},
  issn = {00043702},
  doi = {10.1016/S0004-3702(03)00122-X},
  urldate = {2025-03-30},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {C:\Users\Bulkin\Zotero\storage\QQZRGSQ2\Rissland и др. - 2003 - AI and Law A fruitful synergy.pdf}
}

@misc{mikolovEfficientEstimationWord2013,
  title = {Efficient {{Estimation}} of {{Word Representations}} in {{Vector Space}}},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  year = {2013},
  month = sep,
  number = {arXiv:1301.3781},
  eprint = {1301.3781},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1301.3781},
  urldate = {2025-03-30},
  abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\Bulkin\\Zotero\\storage\\J464P85D\\Mikolov и др. - 2013 - Efficient Estimation of Word Representations in Vector Space.pdf;C\:\\Users\\Bulkin\\Zotero\\storage\\GPA4B3NK\\1301.html}
}

@inproceedings{vaswaniAttentionAllYou2017,
  title = {Attention Is {{All}} You {{Need}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and ukasz Kaiser, {\L} and Polosukhin, Illia},
  year = {2017},
  volume = {30},
  publisher = {Curran Associates, Inc.},
  urldate = {2025-03-30},
  abstract = {The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.},
  file = {C:\Users\Bulkin\Zotero\storage\EJNRUMJ4\Vaswani и др. - 2017 - Attention is All you Need.pdf}
}


@inproceedings{brownLanguageModelsAre2020,
  title = {Language {{Models}} Are {{Few-Shot Learners}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and {Herbert-Voss}, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  year = {2020},
  volume = {33},
  pages = {1877--1901},
  publisher = {Curran Associates, Inc.},
  urldate = {2025-03-30},
  abstract = {We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting.  For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model.  GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.},
  file = {C:\Users\Bulkin\Zotero\storage\7RSQQA4Q\Brown и др. - 2020 - Language Models are Few-Shot Learners.pdf}
}

@misc{laiLargeLanguageModels2023,
  title = {Large {{Language Models}} in {{Law}}: {{A Survey}}},
  shorttitle = {Large {{Language Models}} in {{Law}}},
  author = {Lai, Jinqi and Gan, Wensheng and Wu, Jiayang and Qi, Zhenlian and Yu, Philip S.},
  year = {2023},
  month = nov,
  number = {arXiv:2312.03718},
  eprint = {2312.03718},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2312.03718},
  urldate = {2025-03-20},
  abstract = {The advent of artificial intelligence (AI) has significantly impacted the traditional judicial industry. Moreover, recently, with the development of AI-generated content (AIGC), AI and law have found applications in various domains, including image recognition, automatic text generation, and interactive chat. With the rapid emergence and growing popularity of large models, it is evident that AI will drive transformation in the traditional judicial industry. However, the application of legal large language models (LLMs) is still in its nascent stage. Several challenges need to be addressed. In this paper, we aim to provide a comprehensive survey of legal LLMs. We not only conduct an extensive survey of LLMs, but also expose their applications in the judicial system. We first provide an overview of AI technologies in the legal field and showcase the recent research in LLMs. Then, we discuss the practical implementation presented by legal LLMs, such as providing legal advice to users and assisting judges during trials. In addition, we explore the limitations of legal LLMs, including data, algorithms, and judicial practice. Finally, we summarize practical recommendations and propose future development directions to address these challenges.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\Bulkin\\Zotero\\storage\\FEHKTQNK\\Lai и др. - 2023 - Large Language Models in Law A Survey.pdf;C\:\\Users\\Bulkin\\Zotero\\storage\\F9S6SZWN\\2312.html}
}

@inproceedings{seabrookeSurveyLayPeoples2024,
  title = {A {{Survey}} of {{Lay People}}'s {{Willingness}} to {{Generate Legal Advice}} Using {{Large Language Models}} ({{LLMs}})},
  booktitle = {Proceedings of the {{Second International Symposium}} on {{Trustworthy Autonomous Systems}}},
  author = {Seabrooke, Tina and Schneiders, Eike and Dowthwaite, Liz and Krook, Joshua and Leesakul, Natalie and Clos, Jeremie and Maior, Horia and Fischer, Joel},
  year = {2024},
  month = sep,
  pages = {1--5},
  publisher = {ACM},
  address = {Austin TX USA},
  doi = {10.1145/3686038.3686043},
  urldate = {2025-03-30},
  isbn = {979-8-4007-0989-0},
  langid = {english},
  file = {C:\Users\Bulkin\Zotero\storage\NWUM5DG7\Seabrooke и др. - 2024 - A Survey of Lay People's Willingness to Generate Legal Advice using Large Language Models (LLMs).pdf}
}

@misc{nguyenBriefReportLawGPT2023,
  title = {A {{Brief Report}} on {{LawGPT}} 1.0: {{A Virtual Legal Assistant Based}} on {{GPT-3}}},
  shorttitle = {A {{Brief Report}} on {{LawGPT}} 1.0},
  author = {Nguyen, Ha-Thanh},
  year = {2023},
  month = feb,
  number = {arXiv:2302.05729},
  eprint = {2302.05729},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2302.05729},
  urldate = {2025-03-30},
  abstract = {LawGPT 1.0 is a virtual legal assistant built on the state-of-the-art language model GPT-3, fine-tuned for the legal domain. The system is designed to provide legal assistance to users in a conversational manner, helping them with tasks such as answering legal questions, generating legal documents, and providing legal advice. In this paper, we provide a brief overview of LawGPT 1.0, its architecture, and its performance on a set of legal benchmark tasks. Please note that the detailed information about the model is protected by a non-disclosure agreement (NDA) and cannot be disclosed in this report.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\Bulkin\\Zotero\\storage\\N2ZYXW7G\\Nguyen - 2023 - A Brief Report on LawGPT 1.0 A Virtual Legal Assistant Based on GPT-3.pdf;C\:\\Users\\Bulkin\\Zotero\\storage\\M2Q3M8AG\\2302.html}
}

@misc{cuiChatlawMultiAgentCollaborative2024a,
  title = {Chatlaw: {{A Multi-Agent Collaborative Legal Assistant}} with {{Knowledge Graph Enhanced Mixture-of-Experts Large Language Model}}},
  shorttitle = {Chatlaw},
  author = {Cui, Jiaxi and Ning, Munan and Li, Zongjian and Chen, Bohua and Yan, Yang and Li, Hao and Ling, Bin and Tian, Yonghong and Yuan, Li},
  year = {2024},
  month = may,
  number = {arXiv:2306.16092},
  eprint = {2306.16092},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2306.16092},
  urldate = {2025-03-30},
  abstract = {AI legal assistants based on Large Language Models (LLMs) can provide accessible legal consulting services, but the hallucination problem poses potential legal risks. This paper presents Chatlaw, an innovative legal assistant utilizing a Mixture-of-Experts (MoE) model and a multi-agent system to enhance the reliability and accuracy of AI-driven legal services. By integrating knowledge graphs with artificial screening, we construct a high-quality legal dataset to train the MoE model. This model utilizes different experts to address various legal issues, optimizing the accuracy of legal responses. Additionally, Standardized Operating Procedures (SOP), modeled after real law firm workflows, significantly reduce errors and hallucinations in legal services. Our MoE model outperforms GPT-4 in the Lawbench and Unified Qualification Exam for Legal Professionals by 7.73\% in accuracy and 11 points, respectively, and also surpasses other models in multiple dimensions during real-case consultations, demonstrating our robust capability for legal consultation.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C:\Users\Bulkin\Zotero\storage\MHKUIQRR\Cui и др. - 2024 - Chatlaw A Multi-Agent Collaborative Legal Assistant with Knowledge Graph Enhanced Mixture-of-Expert.pdf}
}

@misc{huangLawyerLLaMATechnical2023,
  title = {Lawyer {{LLaMA Technical Report}}},
  author = {Huang, Quzhe and Tao, Mingxu and Zhang, Chen and An, Zhenwei and Jiang, Cong and Chen, Zhibin and Wu, Zirui and Feng, Yansong},
  year = {2023},
  month = oct,
  number = {arXiv:2305.15062},
  eprint = {2305.15062},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2305.15062},
  urldate = {2025-03-30},
  abstract = {Large Language Models (LLMs), like LLaMA, have exhibited remarkable performance across various tasks. Nevertheless, when deployed to specific domains such as law or medicine, the models still confront the challenge of a deficiency in domain-specific knowledge and an inadequate capability to leverage that knowledge to resolve domain-related problems. In this paper, we propose a new framework to adapt LLMs to specific domains and build Lawyer LLaMA, a legal domain LLM, based on this framework. Specifically, we inject domain knowledge during the continual training stage and teach the model to learn professional skills using properly designed supervised fine-tuning tasks. Moreover, to alleviate the hallucination problem during the model's generation, we add a retrieval module and extract relevant legal articles before the model answers any queries. When learning domain-specific skills, we find that experts' experience is much more useful than experiences distilled from ChatGPT, where hundreds of expert-written data outperform tens of thousands of ChatGPT-generated ones. We will release our model and data.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\Bulkin\\Zotero\\storage\\VEV5BVZ5\\Huang и др. - 2023 - Lawyer LLaMA Technical Report.pdf;C\:\\Users\\Bulkin\\Zotero\\storage\\RCV252QF\\2305.html}
}

@misc{mageshHallucinationFreeAssessingReliability2024a,
  title = {Hallucination-{{Free}}? {{Assessing}} the {{Reliability}} of {{Leading AI Legal Research Tools}}},
  shorttitle = {Hallucination-{{Free}}?},
  author = {Magesh, Varun and Surani, Faiz and Dahl, Matthew and Suzgun, Mirac and Manning, Christopher D. and Ho, Daniel E.},
  year = {2024},
  month = may,
  number = {arXiv:2405.20362},
  eprint = {2405.20362},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2405.20362},
  urldate = {2025-03-30},
  abstract = {Legal practice has witnessed a sharp rise in products incorporating artificial intelligence (AI). Such tools are designed to assist with a wide range of core legal tasks, from search and summarization of caselaw to document drafting. But the large language models used in these tools are prone to "hallucinate," or make up false information, making their use risky in high-stakes domains. Recently, certain legal research providers have touted methods such as retrieval-augmented generation (RAG) as "eliminating" (Casetext, 2023) or "avoid[ing]" hallucinations (Thomson Reuters, 2023), or guaranteeing "hallucination-free" legal citations (LexisNexis, 2023). Because of the closed nature of these systems, systematically assessing these claims is challenging. In this article, we design and report on the first preregistered empirical evaluation of AI-driven legal research tools. We demonstrate that the providers' claims are overstated. While hallucinations are reduced relative to general-purpose chatbots (GPT-4), we find that the AI research tools made by LexisNexis (Lexis+ AI) and Thomson Reuters (Westlaw AI-Assisted Research and Ask Practical Law AI) each hallucinate between 17\% and 33\% of the time. We also document substantial differences between systems in responsiveness and accuracy. Our article makes four key contributions. It is the first to assess and report the performance of RAG-based proprietary legal AI tools. Second, it introduces a comprehensive, preregistered dataset for identifying and understanding vulnerabilities in these systems. Third, it proposes a clear typology for differentiating between hallucinations and accurate legal responses. Last, it provides evidence to inform the responsibilities of legal professionals in supervising and verifying AI outputs, which remains a central open question for the responsible integration of AI into law.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Computers and Society},
  file = {C\:\\Users\\Bulkin\\Zotero\\storage\\ME98BGAX\\Magesh и др. - 2024 - Hallucination-Free Assessing the Reliability of Leading AI Legal Research Tools.pdf;C\:\\Users\\Bulkin\\Zotero\\storage\\ZILRH9Y8\\2405.html}
}

@misc{LawyersGearGenerative,
  title = {Lawyers Gear up for Generative {{AI}}},
  urldate = {2025-03-30},
  abstract = {AI adoption rates accelerate. Yet, UK lawyers demand AI that is grounded in legal sources.},
  howpublished = {https://www.lexisnexis.co.uk/insights/lawyers-cross-into-the-new-era-of-generative-ai/},
  langid = {english}
}

@misc{kalaiCalibratedLanguageModels2024,
  title = {Calibrated {{Language Models Must Hallucinate}}},
  author = {Kalai, Adam Tauman and Vempala, Santosh S.},
  year = {2024},
  month = mar,
  number = {arXiv:2311.14648},
  eprint = {2311.14648},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2311.14648},
  urldate = {2025-03-30},
  abstract = {Recent language models generate false but plausible-sounding text with surprising frequency. Such "hallucinations" are an obstacle to the usability of language-based AI systems and can harm people who rely upon their outputs. This work shows that there is an inherent statistical lower-bound on the rate that pretrained language models hallucinate certain types of facts, having nothing to do with the transformer LM architecture or data quality. For "arbitrary" facts whose veracity cannot be determined from the training data, we show that hallucinations must occur at a certain rate for language models that satisfy a statistical calibration condition appropriate for generative language models. Specifically, if the maximum probability of any fact is bounded, we show that the probability of generating a hallucination is close to the fraction of facts that occur exactly once in the training data (a "Good-Turing" estimate), even assuming ideal training data without errors. One conclusion is that models pretrained to be sufficiently good predictors (i.e., calibrated) may require post-training to mitigate hallucinations on the type of arbitrary facts that tend to appear once in the training set. However, our analysis also suggests that there is no statistical reason that pretraining will lead to hallucination on facts that tend to appear more than once in the training data (like references to publications such as articles and books, whose hallucinations have been particularly notable and problematic) or on systematic facts (like arithmetic calculations). Therefore, different architectures and learning algorithms may mitigate these latter types of hallucinations.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\Bulkin\\Zotero\\storage\\WJRT8QUR\\Kalai и Vempala - 2024 - Calibrated Language Models Must Hallucinate.pdf;C\:\\Users\\Bulkin\\Zotero\\storage\\GMV3DA63\\2311.html}
}

@inproceedings{lewisRetrievalAugmentedGenerationKnowledgeIntensive2020,
  title = {Retrieval-{{Augmented Generation}} for {{Knowledge-Intensive NLP Tasks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and Kutler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and Riedel, Sebastian and Kiela, Douwe},
  year = {2020},
  volume = {33},
  pages = {9459--9474},
  publisher = {Curran Associates, Inc.},
  urldate = {2025-03-21},
  abstract = {Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) -- models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.},
  file = {C:\Users\Bulkin\Zotero\storage\JHYAZZU9\Lewis и др. - 2020 - Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf}
}

@article{kolaScienceCenter,
  author = {Andrey G. Oleynik and Igor O. Datyev and Alexander A. Zuenko and Andrey M. Fedorov and Aleksey V. Shestakov and Ivan G. Vishnyakov},
  title = {Using RAG technology to design an intelligent information system for support exploratory search},
  journal = {Transactions of the Kola Science Centre of RAS. Series: Engineering Sciences},
  volume = {15},
  number = {3},
  year = {2024},
  pages = {5--27},
  doi = {10.37614/2949.1215.2024.15.3.001},  % Add if available
  url = {https://rio.ksc.ru/data/documents/60_3_2024_15_IIMM/60_Trud_Teh_3_2024_15.pdf}
}

@incollection{B,
  pages = {627-637},
  title = {Title of chapter in the book,},
  author = {Sweetser, Penny},
  crossref = {crref}
}
@book{crref,
  title = {Title of Published Book},
  booktitle = {Title of Published Book},
  publisher = {Charles River Media},
  year = {2004},
  address = {Hingham, Massachusetts, USA},
  edition = {1}
}

@ARTICLE{C,
  author = {A. A. Abramson and B. B. Barbie and C. C. Rider},
  title = {Article title},
  journal = {Journal Three},
  year = {1900},
  volume = {1},
  pages = {192--244},
  number = {1}
}

@ARTICLE{D,
  author = {J.K.Author},
  title = {Article title},
  journal = {Journal Three},
  year = {1900},
  month = {6},
  volume = {1},
  pages = {192--244},
  number = {1},
  note="Accessed: June 19, 2005. doi: 10.1109/TTHZ.2016.2544142. [Online]. Available: \url{https://ieeexplore.ieee.org/document/7463081}"
}

@CONFERENCE{F,
  author       = "J\dot K\dot Author",
  title        = "Title of paper",
  booktitle    = "Abbreviated Name of Conf.",
  note         = "1900, pp. 16--19. Accessed: June 19, 2005. [Online]. Available: \url{http://www.computer.org/csdl/proceedings/dac/2003/2394/00/2394001-abs.html}",
}