@article{automation_in_legal_1958,
  author = {D. L. Mehl},
  title = {AUTOMATION IN THE LEGAL WORLD},
  journal = {Mechanisation of Thought Processes},
  year = {1958}
}

@inproceedings{brouard2008legislative,
  title={Legislative Productivity in Comparative Perspective: An Introduction to the Comparative Agendas Project},
  author={Brouard, Sylvain and Baumgartner, Frank and Wilkerson, John and Bevan, Shaun and Breeman, Gerard and Breunig, Christian and Chaques, Laura and Green-Pedersen, Christopher and Jennings, Will and John, Peter and others},
  booktitle={ECPR Joint Sessions},
  year={2008}
}

@article{kullPatternsDatasetShift,
  title = {Patterns of Dataset Shift},
  author = {Kull, Meelis and Flach, Peter},
  abstract = {Dataset shift is a frequent cause of failure of a predictor. A model which performs well in several contexts can give bad predictions in other contexts where the data are shifted compared to the training context. Earlier work has revealed many different causes of shift systematised by Storkey [11] and three important types of effects of shift on probability distributions systematised by Moreno-Torres et al. [8]: covariate shift (distribution shift in attributes), prior probability shift (shift in labels) and concept shift (shift in the relationship between attributes and labels). However, many causes lead to effects not covered by these three types, and hence are called `other types of shift' by Moreno-Torres et al. [8]. We propose a formal notation for the effects of shift using graphical models. We identify 12 patterns of shift (6 of them novel), which cover the effects of all 6 causes described by Storkey [11]. Furthermore, these patterns can be combined to describe effects of multiple or more complex reasons of shift. We see three avenues of work benefitting from our formalism. First, reviewing shift-adaptive methods regarding their applicability range could be done in our notation. Second, identifying patterns of shift in a practical task might aid in finding an existing method to solve the task. Finally, our novel patterns and pattern combinations suggest niches for new shift-adaptive methods.},
  langid = {english},
  file = {C:\Users\Bulkin\Zotero\storage\8P4LK3T2\Kull и Flach - Patterns of dataset shift.pdf}
}

@inproceedings{chenghaozhuYourLLMOutdated2025,
  title = {Is {{Your LLM Outdated}}? {{A Deep Look}} at {{Temporal Generalization}}},
  shorttitle = {Is {{Your LLM Outdated}}?},
  booktitle = {Proceedings of the 2025 {{Conference}} of the {{Nations}} of the {{Americas Chapter}} of the {{Association}} for {{Computational Linguistics}}: {{Human Language Technologies}} ({{Volume}} 1: {{Long Papers}})},
  author = {ChenghaoZhu, ChenghaoZhu and Chen, Nuo and Gao, Yufei and Zhang, Yunyi and Tiwari, Prayag and Wang, Benyou},
  editor = {Chiruzzo, Luis and Ritter, Alan and Wang, Lu},
  year = {2025},
  month = apr,
  pages = {7433--7457},
  publisher = {Association for Computational Linguistics},
  address = {Albuquerque, New Mexico},
  urldate = {2025-05-11},
  abstract = {The rapid advancement of Large Language Models (LLMs) has led to the development of benchmarks that consider temporal dynamics, however, there remains a gap in understanding how well these models can generalize across temporal contexts due to the inherent dynamic nature of language and information. This paper introduces the concept of temporal generalization in LLMs, including bias in past and future generalizations. Then we introduce FreshBench, a new evaluation framework that employs fresh text and event prediction for assessing LLMs' temporal adaptability, ensuring the evaluation process free from data leakage and subjective bias. The experiment shows significant temporal biases and a decline in performance over time.},
  isbn = {979-8-89176-189-6},
  file = {C:\Users\Bulkin\Zotero\storage\EFTDJP4M\ChenghaoZhu и др. - 2025 - Is Your LLM Outdated A Deep Look at Temporal Generalization.pdf}
}

@misc{kalajdzievskiScalingLawsForgetting2024,
  title = {Scaling {{Laws}} for {{Forgetting When Fine-Tuning Large Language Models}}},
  author = {Kalajdzievski, Damjan},
  year = {2024},
  month = jan,
  number = {arXiv:2401.05605},
  eprint = {2401.05605},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2401.05605},
  urldate = {2025-05-11},
  abstract = {We study and quantify the problem of forgetting when fine-tuning pre-trained large language models (LLMs) on a downstream task. We find that parameter-efficient fine-tuning (PEFT) strategies, such as Low-Rank Adapters (LoRA), still suffer from catastrophic forgetting. In particular, we identify a strong inverse linear relationship between the fine-tuning performance and the amount of forgetting when fine-tuning LLMs with LoRA. We further obtain precise scaling laws that show forgetting increases as a shifted power law in the number of parameters fine-tuned and the number of update steps. We also examine the impact of forgetting on knowledge, reasoning, and the safety guardrails trained into Llama 2 7B chat. Our study suggests that forgetting cannot be avoided through early stopping or by varying the number of parameters fine-tuned. We believe this opens up an important safety-critical direction for future research to evaluate and develop fine-tuning schemes which mitigate forgetting},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\Bulkin\\Zotero\\storage\\XSBNAVNG\\Kalajdzievski - 2024 - Scaling Laws for Forgetting When Fine-Tuning Large Language Models.pdf;C\:\\Users\\Bulkin\\Zotero\\storage\\BEGSS8ZP\\2401.html}
}

@inproceedings{zhaiInvestigatingCatastrophicForgetting2024,
  title = {Investigating the {{Catastrophic Forgetting}} in {{Multimodal Large Language Model Fine-Tuning}}},
  booktitle = {Conference on {{Parsimony}} and {{Learning}}},
  author = {Zhai, Yuexiang and Tong, Shengbang and Li, Xiao and Cai, Mu and Qu, Qing and Lee, Yong Jae and Ma, Yi},
  year = {2024},
  month = jan,
  pages = {202--227},
  publisher = {PMLR},
  issn = {2640-3498},
  urldate = {2025-05-11},
  abstract = {Following the success of GPT4, there has been a surge in interest in multimodal large language model (MLLM) research. This line of research focuses on developing general-purpose LLMs through fine-tuning pre-trained LLMs and vision models. However, catastrophic forgetting, a notorious phenomenon where the fine-tuned model fails to retain similar performance compared to the pre-trained model, still remains an inherited problem in multimodal LLMs (MLLM). In this paper, we introduce EMT: Evaluating MulTimodality for evaluating the catastrophic forgetting in MLLMs, by treating each MLLM as an image classifier. We first apply EMT to evaluate several open-source fine-tuned MLLMs and we discover that almost all evaluated MLLMs fail to retain the same performance levels as their vision encoders on standard image classification tasks. Moreover, we continue fine-tuning LLaVA, an MLLM and utilize EMT to assess performance throughout the fine-tuning. Interestingly, our results suggest that early-stage fine-tuning on an image dataset improves performance across other image datasets, by enhancing the alignment of text and language features. However, as fine-tuning proceeds, the MLLMs begin to hallucinate, resulting in a significant loss of generalizability, even when the image encoder remains frozen. Our results suggest that MLLMs have yet to demonstrate performance on par with their vision models on standard image classification tasks and the current MLLM fine-tuning procedure still has room for improvement.},
  langid = {english},
  file = {C:\Users\Bulkin\Zotero\storage\WHE596VC\Zhai и др. - 2024 - Investigating the Catastrophic Forgetting in Multimodal Large Language Model Fine-Tuning.pdf}
}

@article{robinsCatastrophicForgettingRehearsal1995,
  title = {Catastrophic {{Forgetting}}, {{Rehearsal}} and {{Pseudorehearsal}}},
  author = {ROBINS, ANTHONY},
  year = {1995},
  month = jun,
  journal = {Connection Science},
  volume = {7},
  number = {2},
  pages = {123--146},
  publisher = {Taylor & Francis},
  issn = {0954-0091},
  doi = {10.1080/09540099550039318},
  urldate = {2025-05-11},
}

@misc{xiaUnderstandingPerformanceEstimating2024,
  title = {Understanding the {{Performance}} and {{Estimating}} the {{Cost}} of {{LLM Fine-Tuning}}},
  author = {Xia, Yuchen and Kim, Jiho and Chen, Yuhan and Ye, Haojie and Kundu, Souvik and Hao, Cong and Talati, Nishil},
  year = {2024},
  month = aug,
  number = {arXiv:2408.04693},
  eprint = {2408.04693},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2408.04693},
  urldate = {2025-05-11},
  abstract = {Due to the cost-prohibitive nature of training Large Language Models (LLMs), fine-tuning has emerged as an attractive alternative for specializing LLMs for specific tasks using limited compute resources in a cost-effective manner. In this paper, we characterize sparse Mixture of Experts (MoE) based LLM fine-tuning to understand their accuracy and runtime performance on a single GPU. Our evaluation provides unique insights into the training efficacy of sparse and dense versions of MoE models, as well as their runtime characteristics, including maximum batch size, execution time breakdown, end-to-end throughput, GPU hardware utilization, and load distribution. Our study identifies the optimization of the MoE layer as crucial for further improving the performance of LLM fine-tuning. Using our profiling results, we also develop and validate an analytical model to estimate the cost of LLM fine-tuning on the cloud. This model, based on parameters of the model and GPU architecture, estimates LLM throughput and the cost of training, aiding practitioners in industry and academia to budget the cost of fine-tuning a specific model.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\Bulkin\\Zotero\\storage\\9VF3TSZF\\Xia и др. - 2024 - Understanding the Performance and Estimating the Cost of LLM Fine-Tuning.pdf;C\:\\Users\\Bulkin\\Zotero\\storage\\9MNNNJH7\\2408.html}
}

@misc{jiangMixtralExperts2024,
  title = {Mixtral of {{Experts}}},
  author = {Jiang, Albert Q. and Sablayrolles, Alexandre and Roux, Antoine and Mensch, Arthur and Savary, Blanche and Bamford, Chris and Chaplot, Devendra Singh and de las Casas, Diego and Hanna, Emma Bou and Bressand, Florian and Lengyel, Gianna and Bour, Guillaume and Lample, Guillaume and Lavaud, L{\'e}lio Renard and Saulnier, Lucile and Lachaux, Marie-Anne and Stock, Pierre and Subramanian, Sandeep and Yang, Sophia and Antoniak, Szymon and Scao, Teven Le and Gervet, Th{\'e}ophile and Lavril, Thibaut and Wang, Thomas and Lacroix, Timoth{\'e}e and Sayed, William El},
  year = {2024},
  month = jan,
  number = {arXiv:2401.04088},
  eprint = {2401.04088},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2401.04088},
  urldate = {2025-05-11},
  abstract = {We introduce Mixtral 8x7B, a Sparse Mixture of Experts (SMoE) language model. Mixtral has the same architecture as Mistral 7B, with the difference that each layer is composed of 8 feedforward blocks (i.e. experts). For every token, at each layer, a router network selects two experts to process the current state and combine their outputs. Even though each token only sees two experts, the selected experts can be different at each timestep. As a result, each token has access to 47B parameters, but only uses 13B active parameters during inference. Mixtral was trained with a context size of 32k tokens and it outperforms or matches Llama 2 70B and GPT-3.5 across all evaluated benchmarks. In particular, Mixtral vastly outperforms Llama 2 70B on mathematics, code generation, and multilingual benchmarks. We also provide a model fine-tuned to follow instructions, Mixtral 8x7B - Instruct, that surpasses GPT-3.5 Turbo, Claude-2.1, Gemini Pro, and Llama 2 70B - chat model on human benchmarks. Both the base and instruct models are released under the Apache 2.0 license.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\Bulkin\\Zotero\\storage\\466BLNKK\\Jiang и др. - 2024 - Mixtral of Experts.pdf;C\:\\Users\\Bulkin\\Zotero\\storage\\KFT38E4U\\2401.html}
}

@misc{cobbeTrainingVerifiersSolve2021,
  title = {Training {{Verifiers}} to {{Solve Math Word Problems}}},
  author = {Cobbe, Karl and Kosaraju, Vineet and Bavarian, Mohammad and Chen, Mark and Jun, Heewoo and Kaiser, Lukasz and Plappert, Matthias and Tworek, Jerry and Hilton, Jacob and Nakano, Reiichiro and Hesse, Christopher and Schulman, John},
  year = {2021},
  month = nov,
  number = {arXiv:2110.14168},
  eprint = {2110.14168},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2110.14168},
  urldate = {2025-05-11},
  abstract = {State-of-the-art language models can match human performance on many tasks, but they still struggle to robustly perform multi-step mathematical reasoning. To diagnose the failures of current models and support research, we introduce GSM8K, a dataset of 8.5K high quality linguistically diverse grade school math word problems. We find that even the largest transformer models fail to achieve high test performance, despite the conceptual simplicity of this problem distribution. To increase performance, we propose training verifiers to judge the correctness of model completions. At test time, we generate many candidate solutions and select the one ranked highest by the verifier. We demonstrate that verification significantly improves performance on GSM8K, and we provide strong empirical evidence that verification scales more effectively with increased data than a finetuning baseline.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\Bulkin\\Zotero\\storage\\K2LED2PA\\Cobbe и др. - 2021 - Training Verifiers to Solve Math Word Problems.pdf;C\:\\Users\\Bulkin\\Zotero\\storage\\ZB5ULPKL\\2110.html}
}




@inproceedings{weaverTranslation1952,
  title = {Translation},
  booktitle = {Proceedings of the {{Conference}} on {{Mechanical Translation}}},
  author = {Weaver, Warren},
  year = {1952},
  address = {Massachusetts Institute of Technology},
  urldate = {2025-03-30},
  file = {C:\Users\Bulkin\Zotero\storage\DN7I9A2I\Weaver - 1952 - Translation.pdf}
}

@article{brownStatisticalApproachMachine1990,
  title = {A {{Statistical Approach}} to {{Machine Translation}}},
  author = {Brown, Peter F. and Cocke, John and Della Pietra, Stephen A. and Della Pietra, Vincent J. and Jelinek, Fredrick and Lafferty, John D. and Mercer, Robert L. and Roossin, Paul S.},
  year = {1990},
  journal = {Computational Linguistics},
  volume = {16},
  number = {2},
  pages = {79--85},
  urldate = {2025-03-30},
  file = {C:\Users\Bulkin\Zotero\storage\LBZXV7DH\Brown и др. - 1990 - A Statistical Approach to Machine Translation.pdf}
}

@article{merigouxCatalaProgrammingLanguage2021,
  title = {Catala: {{A Programming Language}} for the {{Law}}},
  shorttitle = {Catala},
  author = {Merigoux, Denis and Chataing, Nicolas and Protzenko, Jonathan},
  year = {2021},
  journal = {Proceedings of the ACM on Programming Languages},
  volume = {5},
  number = {ICFP},
  pages = {77:1},
  doi = {10.1145/3473582},
  urldate = {2025-03-30},
  abstract = {Law at large underpins modern society, codifying and governing many aspects of citizens' daily lives. Oftentimes, law is subject to interpretation, debate and challenges throughout various courts and jurisdictions. But in some other areas, law leaves little room for interpretation, and essentially aims to rigorously describe a computation, a decision procedure or, simply said, an algorithm. Unfortunately, prose remains a woefully inadequate tool for the job. The lack of formalism leaves room for ambiguities; the structure of legal statutes, with many paragraphs and subsections spread across multiple pages, makes it hard to compute the intended outcome of the algorithm underlying a given text; and, as with any other piece of poorly-specified critical software, the use of informal, natural language leaves corner cases unaddressed. We introduce Catala, a new programming language that we specifically designed to allow a straightforward and systematic translation of statutory law into an executable implementation. Catala aims to bring together lawyers and programmers through a shared medium, which together they can understand, edit and evolve, bridging a gap that too often results in dramatically incorrect implementations of the law. We have implemented a compiler for Catala, and have proven the correctness of its core compilation steps using the F {$\star$} proof assistant. We evaluate Catala on several legal texts that are algorithms in disguise, notably section 121 of the US federal income tax and the byzantine French family benefits; in doing so, we uncover a bug in the official implementation of the French benefits. We observe as a consequence of the formalization process that using Catala enables rich interactions between lawyers and programmers, leading to a greater understanding of the original legislative intent, while producing a correct-by-construction executable specification reusable by the greater software ecosystem. Doing so, Catala increases trust in legal institutions, and mitigates the risk of societal damage due to incorrect implementations of the law.},
  langid = {english},
  file = {C:\Users\Bulkin\Zotero\storage\BXJLTKJH\Merigoux и др. - 2021 - Catala A Programming Language for the Law.pdf}
}


@article{risslandAILawFruitful2003,
  title = {{{AI}} and {{Law}}: {{A}} Fruitful Synergy},
  shorttitle = {{{AI}} and {{Law}}},
  author = {Rissland, Edwina L. and Ashley, Kevin D. and Loui, R.P.},
  year = {2003},
  month = nov,
  journal = {Artificial Intelligence},
  volume = {150},
  number = {1-2},
  pages = {1--15},
  issn = {00043702},
  doi = {10.1016/S0004-3702(03)00122-X},
  urldate = {2025-03-30},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  langid = {english},
  file = {C:\Users\Bulkin\Zotero\storage\QQZRGSQ2\Rissland и др. - 2003 - AI and Law A fruitful synergy.pdf}
}

@misc{mikolovEfficientEstimationWord2013,
  title = {Efficient {{Estimation}} of {{Word Representations}} in {{Vector Space}}},
  author = {Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  year = {2013},
  month = sep,
  number = {arXiv:1301.3781},
  eprint = {1301.3781},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1301.3781},
  urldate = {2025-03-30},
  abstract = {We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\Bulkin\\Zotero\\storage\\J464P85D\\Mikolov и др. - 2013 - Efficient Estimation of Word Representations in Vector Space.pdf;C\:\\Users\\Bulkin\\Zotero\\storage\\GPA4B3NK\\1301.html}
}

@inproceedings{vaswaniAttentionAllYou2017,
  title = {Attention Is {{All}} You {{Need}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and ukasz Kaiser, {\L} and Polosukhin, Illia},
  year = {2017},
  volume = {30},
  publisher = {Curran Associates, Inc.},
  urldate = {2025-03-30},
  abstract = {The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.},
  file = {C:\Users\Bulkin\Zotero\storage\EJNRUMJ4\Vaswani и др. - 2017 - Attention is All you Need.pdf}
}


@inproceedings{brownLanguageModelsAre2020,
  title = {Language {{Models}} Are {{Few-Shot Learners}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and {Herbert-Voss}, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
  year = {2020},
  volume = {33},
  pages = {1877--1901},
  publisher = {Curran Associates, Inc.},
  urldate = {2025-03-30},
  abstract = {We demonstrate that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even becoming competitive with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting.  For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model.  GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks. We also identify some datasets where GPT-3's few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora.},
  file = {C:\Users\Bulkin\Zotero\storage\7RSQQA4Q\Brown и др. - 2020 - Language Models are Few-Shot Learners.pdf}
}

@misc{laiLargeLanguageModels2023,
  title = {Large {{Language Models}} in {{Law}}: {{A Survey}}},
  shorttitle = {Large {{Language Models}} in {{Law}}},
  author = {Lai, Jinqi and Gan, Wensheng and Wu, Jiayang and Qi, Zhenlian and Yu, Philip S.},
  year = {2023},
  month = nov,
  number = {arXiv:2312.03718},
  eprint = {2312.03718},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2312.03718},
  urldate = {2025-03-20},
  abstract = {The advent of artificial intelligence (AI) has significantly impacted the traditional judicial industry. Moreover, recently, with the development of AI-generated content (AIGC), AI and law have found applications in various domains, including image recognition, automatic text generation, and interactive chat. With the rapid emergence and growing popularity of large models, it is evident that AI will drive transformation in the traditional judicial industry. However, the application of legal large language models (LLMs) is still in its nascent stage. Several challenges need to be addressed. In this paper, we aim to provide a comprehensive survey of legal LLMs. We not only conduct an extensive survey of LLMs, but also expose their applications in the judicial system. We first provide an overview of AI technologies in the legal field and showcase the recent research in LLMs. Then, we discuss the practical implementation presented by legal LLMs, such as providing legal advice to users and assisting judges during trials. In addition, we explore the limitations of legal LLMs, including data, algorithms, and judicial practice. Finally, we summarize practical recommendations and propose future development directions to address these challenges.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\Bulkin\\Zotero\\storage\\FEHKTQNK\\Lai и др. - 2023 - Large Language Models in Law A Survey.pdf;C\:\\Users\\Bulkin\\Zotero\\storage\\F9S6SZWN\\2312.html}
}

@inproceedings{seabrookeSurveyLayPeoples2024,
  title = {A {{Survey}} of {{Lay People}}'s {{Willingness}} to {{Generate Legal Advice}} Using {{Large Language Models}} ({{LLMs}})},
  booktitle = {Proceedings of the {{Second International Symposium}} on {{Trustworthy Autonomous Systems}}},
  author = {Seabrooke, Tina and Schneiders, Eike and Dowthwaite, Liz and Krook, Joshua and Leesakul, Natalie and Clos, Jeremie and Maior, Horia and Fischer, Joel},
  year = {2024},
  month = sep,
  pages = {1--5},
  publisher = {ACM},
  address = {Austin TX USA},
  doi = {10.1145/3686038.3686043},
  urldate = {2025-03-30},
  isbn = {979-8-4007-0989-0},
  langid = {english},
  file = {C:\Users\Bulkin\Zotero\storage\NWUM5DG7\Seabrooke и др. - 2024 - A Survey of Lay People's Willingness to Generate Legal Advice using Large Language Models (LLMs).pdf}
}

@misc{nguyenBriefReportLawGPT2023,
  title = {A {{Brief Report}} on {{LawGPT}} 1.0: {{A Virtual Legal Assistant Based}} on {{GPT-3}}},
  shorttitle = {A {{Brief Report}} on {{LawGPT}} 1.0},
  author = {Nguyen, Ha-Thanh},
  year = {2023},
  month = feb,
  number = {arXiv:2302.05729},
  eprint = {2302.05729},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2302.05729},
  urldate = {2025-03-30},
  abstract = {LawGPT 1.0 is a virtual legal assistant built on the state-of-the-art language model GPT-3, fine-tuned for the legal domain. The system is designed to provide legal assistance to users in a conversational manner, helping them with tasks such as answering legal questions, generating legal documents, and providing legal advice. In this paper, we provide a brief overview of LawGPT 1.0, its architecture, and its performance on a set of legal benchmark tasks. Please note that the detailed information about the model is protected by a non-disclosure agreement (NDA) and cannot be disclosed in this report.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\Bulkin\\Zotero\\storage\\N2ZYXW7G\\Nguyen - 2023 - A Brief Report on LawGPT 1.0 A Virtual Legal Assistant Based on GPT-3.pdf;C\:\\Users\\Bulkin\\Zotero\\storage\\M2Q3M8AG\\2302.html}
}

@misc{cuiChatlawMultiAgentCollaborative2024a,
  title = {Chatlaw: {{A Multi-Agent Collaborative Legal Assistant}} with {{Knowledge Graph Enhanced Mixture-of-Experts Large Language Model}}},
  shorttitle = {Chatlaw},
  author = {Cui, Jiaxi and Ning, Munan and Li, Zongjian and Chen, Bohua and Yan, Yang and Li, Hao and Ling, Bin and Tian, Yonghong and Yuan, Li},
  year = {2024},
  month = may,
  number = {arXiv:2306.16092},
  eprint = {2306.16092},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2306.16092},
  urldate = {2025-03-30},
  abstract = {AI legal assistants based on Large Language Models (LLMs) can provide accessible legal consulting services, but the hallucination problem poses potential legal risks. This paper presents Chatlaw, an innovative legal assistant utilizing a Mixture-of-Experts (MoE) model and a multi-agent system to enhance the reliability and accuracy of AI-driven legal services. By integrating knowledge graphs with artificial screening, we construct a high-quality legal dataset to train the MoE model. This model utilizes different experts to address various legal issues, optimizing the accuracy of legal responses. Additionally, Standardized Operating Procedures (SOP), modeled after real law firm workflows, significantly reduce errors and hallucinations in legal services. Our MoE model outperforms GPT-4 in the Lawbench and Unified Qualification Exam for Legal Professionals by 7.73\% in accuracy and 11 points, respectively, and also surpasses other models in multiple dimensions during real-case consultations, demonstrating our robust capability for legal consultation.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C:\Users\Bulkin\Zotero\storage\MHKUIQRR\Cui и др. - 2024 - Chatlaw A Multi-Agent Collaborative Legal Assistant with Knowledge Graph Enhanced Mixture-of-Expert.pdf}
}

@misc{huangLawyerLLaMATechnical2023,
  title = {Lawyer {{LLaMA Technical Report}}},
  author = {Huang, Quzhe and Tao, Mingxu and Zhang, Chen and An, Zhenwei and Jiang, Cong and Chen, Zhibin and Wu, Zirui and Feng, Yansong},
  year = {2023},
  month = oct,
  number = {arXiv:2305.15062},
  eprint = {2305.15062},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2305.15062},
  urldate = {2025-03-30},
  abstract = {Large Language Models (LLMs), like LLaMA, have exhibited remarkable performance across various tasks. Nevertheless, when deployed to specific domains such as law or medicine, the models still confront the challenge of a deficiency in domain-specific knowledge and an inadequate capability to leverage that knowledge to resolve domain-related problems. In this paper, we propose a new framework to adapt LLMs to specific domains and build Lawyer LLaMA, a legal domain LLM, based on this framework. Specifically, we inject domain knowledge during the continual training stage and teach the model to learn professional skills using properly designed supervised fine-tuning tasks. Moreover, to alleviate the hallucination problem during the model's generation, we add a retrieval module and extract relevant legal articles before the model answers any queries. When learning domain-specific skills, we find that experts' experience is much more useful than experiences distilled from ChatGPT, where hundreds of expert-written data outperform tens of thousands of ChatGPT-generated ones. We will release our model and data.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\Bulkin\\Zotero\\storage\\VEV5BVZ5\\Huang и др. - 2023 - Lawyer LLaMA Technical Report.pdf;C\:\\Users\\Bulkin\\Zotero\\storage\\RCV252QF\\2305.html}
}

@misc{mageshHallucinationFreeAssessingReliability2024a,
  title = {Hallucination-{{Free}}? {{Assessing}} the {{Reliability}} of {{Leading AI Legal Research Tools}}},
  shorttitle = {Hallucination-{{Free}}?},
  author = {Magesh, Varun and Surani, Faiz and Dahl, Matthew and Suzgun, Mirac and Manning, Christopher D. and Ho, Daniel E.},
  year = {2024},
  month = may,
  number = {arXiv:2405.20362},
  eprint = {2405.20362},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2405.20362},
  urldate = {2025-03-30},
  abstract = {Legal practice has witnessed a sharp rise in products incorporating artificial intelligence (AI). Such tools are designed to assist with a wide range of core legal tasks, from search and summarization of caselaw to document drafting. But the large language models used in these tools are prone to "hallucinate," or make up false information, making their use risky in high-stakes domains. Recently, certain legal research providers have touted methods such as retrieval-augmented generation (RAG) as "eliminating" (Casetext, 2023) or "avoid[ing]" hallucinations (Thomson Reuters, 2023), or guaranteeing "hallucination-free" legal citations (LexisNexis, 2023). Because of the closed nature of these systems, systematically assessing these claims is challenging. In this article, we design and report on the first preregistered empirical evaluation of AI-driven legal research tools. We demonstrate that the providers' claims are overstated. While hallucinations are reduced relative to general-purpose chatbots (GPT-4), we find that the AI research tools made by LexisNexis (Lexis+ AI) and Thomson Reuters (Westlaw AI-Assisted Research and Ask Practical Law AI) each hallucinate between 17\% and 33\% of the time. We also document substantial differences between systems in responsiveness and accuracy. Our article makes four key contributions. It is the first to assess and report the performance of RAG-based proprietary legal AI tools. Second, it introduces a comprehensive, preregistered dataset for identifying and understanding vulnerabilities in these systems. Third, it proposes a clear typology for differentiating between hallucinations and accurate legal responses. Last, it provides evidence to inform the responsibilities of legal professionals in supervising and verifying AI outputs, which remains a central open question for the responsible integration of AI into law.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Computers and Society},
  file = {C\:\\Users\\Bulkin\\Zotero\\storage\\ME98BGAX\\Magesh и др. - 2024 - Hallucination-Free Assessing the Reliability of Leading AI Legal Research Tools.pdf;C\:\\Users\\Bulkin\\Zotero\\storage\\ZILRH9Y8\\2405.html}
}

@misc{LawyersGearGenerative,
  title = {Lawyers Gear up for Generative {{AI}}},
  urldate = {2025-03-30},
  abstract = {AI adoption rates accelerate. Yet, UK lawyers demand AI that is grounded in legal sources.},
  howpublished = {https://www.lexisnexis.co.uk/insights/lawyers-cross-into-the-new-era-of-generative-ai/},
  langid = {english}
}

@misc{kalaiCalibratedLanguageModels2024,
  title = {Calibrated {{Language Models Must Hallucinate}}},
  author = {Kalai, Adam Tauman and Vempala, Santosh S.},
  year = {2024},
  month = mar,
  number = {arXiv:2311.14648},
  eprint = {2311.14648},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2311.14648},
  urldate = {2025-03-30},
  abstract = {Recent language models generate false but plausible-sounding text with surprising frequency. Such "hallucinations" are an obstacle to the usability of language-based AI systems and can harm people who rely upon their outputs. This work shows that there is an inherent statistical lower-bound on the rate that pretrained language models hallucinate certain types of facts, having nothing to do with the transformer LM architecture or data quality. For "arbitrary" facts whose veracity cannot be determined from the training data, we show that hallucinations must occur at a certain rate for language models that satisfy a statistical calibration condition appropriate for generative language models. Specifically, if the maximum probability of any fact is bounded, we show that the probability of generating a hallucination is close to the fraction of facts that occur exactly once in the training data (a "Good-Turing" estimate), even assuming ideal training data without errors. One conclusion is that models pretrained to be sufficiently good predictors (i.e., calibrated) may require post-training to mitigate hallucinations on the type of arbitrary facts that tend to appear once in the training set. However, our analysis also suggests that there is no statistical reason that pretraining will lead to hallucination on facts that tend to appear more than once in the training data (like references to publications such as articles and books, whose hallucinations have been particularly notable and problematic) or on systematic facts (like arithmetic calculations). Therefore, different architectures and learning algorithms may mitigate these latter types of hallucinations.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\Bulkin\\Zotero\\storage\\WJRT8QUR\\Kalai и Vempala - 2024 - Calibrated Language Models Must Hallucinate.pdf;C\:\\Users\\Bulkin\\Zotero\\storage\\GMV3DA63\\2311.html}
}

@inproceedings{lewisRetrievalAugmentedGenerationKnowledgeIntensive2020,
  title = {Retrieval-{{Augmented Generation}} for {{Knowledge-Intensive NLP Tasks}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and Kutler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and Riedel, Sebastian and Kiela, Douwe},
  year = {2020},
  volume = {33},
  pages = {9459--9474},
  publisher = {Curran Associates, Inc.},
  urldate = {2025-03-21},
  abstract = {Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) -- models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.},
  file = {C:\Users\Bulkin\Zotero\storage\JHYAZZU9\Lewis и др. - 2020 - Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf}
}

@article{kolaScienceCenter,
  author = {Andrey G. Oleynik and Igor O. Datyev and Alexander A. Zuenko and Andrey M. Fedorov and Aleksey V. Shestakov and Ivan G. Vishnyakov},
  title = {Using RAG technology to design an intelligent information system for support exploratory search},
  journal = {Transactions of the Kola Science Centre of RAS. Series: Engineering Sciences},
  volume = {15},
  number = {3},
  year = {2024},
  pages = {5--27},
  doi = {10.37614/2949.1215.2024.15.3.001},  % Add if available
  url = {https://rio.ksc.ru/data/documents/60_3_2024_15_IIMM/60_Trud_Teh_3_2024_15.pdf}
}

@incollection{B,
  pages = {627-637},
  title = {Title of chapter in the book,},
  author = {Sweetser, Penny},
  crossref = {crref}
}
@book{crref,
  title = {Title of Published Book},
  booktitle = {Title of Published Book},
  publisher = {Charles River Media},
  year = {2004},
  address = {Hingham, Massachusetts, USA},
  edition = {1}
}

@ARTICLE{C,
  author = {A. A. Abramson and B. B. Barbie and C. C. Rider},
  title = {Article title},
  journal = {Journal Three},
  year = {1900},
  volume = {1},
  pages = {192--244},
  number = {1}
}

@ARTICLE{D,
  author = {J.K.Author},
  title = {Article title},
  journal = {Journal Three},
  year = {1900},
  month = {6},
  volume = {1},
  pages = {192--244},
  number = {1},
  note="Accessed: June 19, 2005. doi: 10.1109/TTHZ.2016.2544142. [Online]. Available: \url{https://ieeexplore.ieee.org/document/7463081}"
}

@CONFERENCE{F,
  author       = "J\dot K\dot Author",
  title        = "Title of paper",
  booktitle    = "Abbreviated Name of Conf.",
  note         = "1900, pp. 16--19. Accessed: June 19, 2005. [Online]. Available: \url{http://www.computer.org/csdl/proceedings/dac/2003/2394/00/2394001-abs.html}",
}