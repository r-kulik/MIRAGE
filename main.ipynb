{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# In a Jupyter Notebook cell\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "print(np.__version__)\n",
    "from mirage import WordCountingChunkingAlgorithm, FolderRawStorage, WhooshChunkStorage\n",
    "from mirage import HuggingFaceEmbedder, TextNormalizer\n",
    "from mirage import NatashaSentenceChunking, SemanticChunking\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = HuggingFaceEmbedder(model_name='BAAI/bge-m3', normalizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "\n",
    "documents = FolderRawStorage('data_test')\n",
    " # тут заменить на нужную папку\n",
    "chunks = WhooshChunkStorage(scoring_function=\"BM25F\", normalizer=True)\n",
    "# algorithm = WordCountingChunkingAlgorithm(documents, chunks, words_amount=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting text into the sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "611it [00:00, 50276.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating embeddings of the sentences for semantic grouping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 611/611 [00:58<00:00, 10.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding chunks to the storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 427/427 [00:02<00:00, 150.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "algorithm = SemanticChunking(raw_storage=documents, chunk_storage=chunks, embedder=embedder, threshold=0.5, max_chunk_size=1000)\n",
    "algorithm.execute(visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Этот маленький ребус он послал нам с первой почтой, а сам выехал сюда ближайшим поездом.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "index = chunks.get_indexes()[random.randint(1, 50)]\n",
    "print(len(chunks[index]))\n",
    "chunks[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ChunkStorage to VectorIndex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 427/427 [00:43<00:00,  9.85it/s]\n"
     ]
    }
   ],
   "source": [
    "from mirage.index.vector_index.ram_vector_index import L2RAMVectorIndex\n",
    "from mirage import FaissIndexFlatL2, FaissIndexIVFPQR\n",
    "vector_index = FaissIndexIVFPQR(dimensionality=embedder.get_dimensionality())\n",
    "embedder.convert_chunks_to_vector_index(chunks, vector_index, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[QueryResult(score=0.8335791230201721, chunk_storage_key='376f5652-13c7-4e6b-afb0-45bfbb531550', vector=array([ 0.01070768,  0.01809778, -0.03436125, ..., -0.01930608,\n",
      "       -0.01730648,  0.04182574], dtype=float32)), QueryResult(score=0.8566122055053711, chunk_storage_key='e17fd7c4-af4e-4411-8db6-4273c7e5c9d0', vector=array([-0.0221016 ,  0.01742174, -0.07253658, ..., -0.06477947,\n",
      "       -0.04252745,  0.03287837], dtype=float32)), QueryResult(score=0.8726161122322083, chunk_storage_key='9c27a6d0-ce9c-4aca-a3a0-71d5dfb97aac', vector=array([-0.00987871,  0.03530333, -0.04278317, ..., -0.03488935,\n",
      "       -0.04346183,  0.03543985], dtype=float32)), QueryResult(score=0.8734219670295715, chunk_storage_key='9c084351-b6e4-46bd-9b40-3042d0ef9bb1', vector=array([ 0.01042651,  0.0605932 , -0.05291994, ...,  0.00316011,\n",
      "        0.02510138,  0.02404919], dtype=float32)), QueryResult(score=0.8924689292907715, chunk_storage_key='418a5eff-8198-433d-970b-80cb6ed0c595', vector=array([-0.00151548,  0.0361762 , -0.03660547, ..., -0.05836364,\n",
      "       -0.01141903,  0.02464006], dtype=float32)), QueryResult(score=0.8948429822921753, chunk_storage_key='bfab13ac-3b44-42cd-9aeb-3f1cc874bea9', vector=array([-0.02815668,  0.02359498, -0.04920556, ..., -0.00595306,\n",
      "       -0.06675137,  0.03710842], dtype=float32)), QueryResult(score=0.929951012134552, chunk_storage_key='a6baad31-ea4e-48e8-a72b-06d75535bd19', vector=array([ 0.04096003,  0.00857711, -0.03251835, ..., -0.06363682,\n",
      "       -0.02091081,  0.02382073], dtype=float32)), QueryResult(score=0.9746432304382324, chunk_storage_key='385be763-faf5-4a95-a1c6-44625e92a8fe', vector=array([-0.03565086, -0.00672048, -0.03559105, ..., -0.02535343,\n",
      "       -0.04985633,  0.00621269], dtype=float32)), QueryResult(score=0.9803217649459839, chunk_storage_key='c4828844-0584-4c1c-ba4b-4f21860aaf33', vector=array([ 0.01296398,  0.04448763, -0.02153989, ..., -0.00860809,\n",
      "       -0.01165262,  0.02061996], dtype=float32)), QueryResult(score=0.9977196455001831, chunk_storage_key='9e6a7c18-8ec3-4157-adf2-7cc210ff5d86', vector=array([-0.00534553,  0.05100093, -0.00502173, ..., -0.01300563,\n",
      "       -0.05078004, -0.00975566], dtype=float32)), QueryResult(score=1.003746509552002, chunk_storage_key='34d829ab-caab-4580-85b4-bba6bccd1b28', vector=array([ 0.03927579,  0.00241104, -0.04921697, ..., -0.04862007,\n",
      "       -0.00518589,  0.04830282], dtype=float32)), QueryResult(score=1.0152220726013184, chunk_storage_key='b3cfce21-e1d5-4520-8533-b6344f049728', vector=array([-0.02690054, -0.00039792, -0.03753845, ..., -0.00540887,\n",
      "       -0.02363675,  0.03632394], dtype=float32)), QueryResult(score=1.01560640335083, chunk_storage_key='8271b145-5fe2-4527-addf-4559e66083ee', vector=array([ 0.04850505,  0.02253365, -0.0156807 , ..., -0.02308475,\n",
      "       -0.01036364,  0.04039319], dtype=float32)), QueryResult(score=1.0271902084350586, chunk_storage_key='570e6cda-8b72-4bb1-b306-bb81b62a4cc4', vector=array([ 0.00278152, -0.01837112, -0.0608447 , ...,  0.01513056,\n",
      "       -0.03044043, -0.00596537], dtype=float32)), QueryResult(score=1.0438331365585327, chunk_storage_key='ee331343-21f1-43d9-9259-d7d273fbe833', vector=array([-0.01058295,  0.01733731, -0.05892041, ..., -0.00618152,\n",
      "       -0.03350652,  0.02498114], dtype=float32)), QueryResult(score=1.0458725690841675, chunk_storage_key='215ee618-aff7-4829-83d9-cc2b831a5f72', vector=array([-0.02262008, -0.02146637, -0.08182973, ...,  0.00526252,\n",
      "       -0.0244448 ,  0.03740615], dtype=float32)), QueryResult(score=1.0471690893173218, chunk_storage_key='857c85d7-31d5-48bd-9e64-8b8f16c9effd', vector=array([-0.05637475,  0.01963601, -0.04920856, ..., -0.00271543,\n",
      "       -0.00270449, -0.01442451], dtype=float32)), QueryResult(score=1.0567314624786377, chunk_storage_key='13e29002-b67d-40f6-a14e-188f147b0dd6', vector=array([-0.04067627,  0.00211853, -0.04102436, ...,  0.00223519,\n",
      "        0.01118694,  0.04086076], dtype=float32)), QueryResult(score=1.0579125881195068, chunk_storage_key='66586142-7456-4239-8f9c-98d38c34f34a', vector=array([-0.00148415,  0.03544216, -0.02222475, ..., -0.02405533,\n",
      "       -0.0176066 ,  0.05267358], dtype=float32)), QueryResult(score=1.0834579467773438, chunk_storage_key='76776b4e-438f-4fc5-98f8-e754a1ac88d4', vector=array([-0.05004463, -0.01292033, -0.05980106, ..., -0.03208277,\n",
      "        0.01935327,  0.05686688], dtype=float32))]\n"
     ]
    }
   ],
   "source": [
    "query = 'убитая женщина'\n",
    "query_vector = embedder.embed(text=query)\n",
    "# print(query_vector)\n",
    "vector_answer = vector_index.query(\n",
    "    query_vector, top_k=20\n",
    ")\n",
    "print(vector_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of vectors loaded in quorum: 189193\n",
      "word \"быть\" is presented in word vectors: True\n",
      "set of POS in w2v model: {'PROPN', 'X', 'NOUN', 'VERB', 'ADV', 'INTJ', 'ADJ', 'SYM', 'NUM'}\n",
      "Rules of synonimization: {'ADJ': 0.5, 'VERB': 0.65}\n",
      " For word \"убитая\" obtained synonims:\n",
      "[('убитый_VERB', 0.7544418573379517), ('убивать_NOUN', 0.6665365695953369), ('убитый_NOUN', 0.6586453318595886), ('убивать_ADJ', 0.6549819111824036), ('убить_ADJ', 0.6502050161361694), ('убить_VERB', 0.6136346459388733), ('труп_NOUN', 0.5793484449386597), ('убивать_VERB', 0.561595618724823), ('раненый_ADJ', 0.526347815990448), ('окровавленный_ADJ', 0.5030656456947327), ('окровавливать_VERB', 0.4972875118255615), ('окровавленный_VERB', 0.494367778301239), ('бездыхать_ADJ', 0.4913272559642792), ('бездыханный_ADJ', 0.4852805435657501), ('ранить_ADJ', 0.48326724767684937), ('раненый_NOUN', 0.47747743129730225), ('окровавить_ADJ', 0.4754990339279175), ('стрелявший_VERB', 0.46570515632629395), ('убийца_NOUN', 0.4600498676300049), ('окровавить_VERB', 0.4569088816642761)]\n",
      "SEARCH QUERY with sim 0.0: убитая женщина\n",
      "SEARCH QUERY with sim 0.6665365695953369: убивать женщина\n",
      "SEARCH QUERY with sim 0.6502050161361694: убить женщина\n",
      "SEARCH QUERY with sim 0.5793484449386597: труп женщина\n",
      "SEARCH QUERY with sim 0.526347815990448: раненый женщина\n",
      "SEARCH QUERY with sim 0.5030656456947327: окровавленная женщина\n"
     ]
    }
   ],
   "source": [
    "from mirage.inference.quorums.RusVectoresQuorum import RusVectoresQuorum\n",
    "\n",
    "\n",
    "quorum = RusVectoresQuorum(\n",
    "    chunk_storage=chunks, \n",
    "    path_to_model='mirage\\inference\\quorums\\model.bin',\n",
    "    POS_thresholds={\"ADJ\": 0.5, \"VERB\": 0.65},\n",
    "    visualize=True,\n",
    "    max_combinations=25)\n",
    "fulltext_search_answer = quorum.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mirage.inference.rerankers.LinearCombinationReranker import LinearCombinationReranker\n",
    "\n",
    "rank_fusion = LinearCombinationReranker(fulltext_score_weight=0.25, vector_score_weight=1)\n",
    "ranked_answer = rank_fusion(fulltext_search_answer, vector_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['— Вы трогали убитого? — спросил Холме.',\n",
       " '— Его несомненно закрыла женщина, закрыла инстинктивно…',\n",
       " 'Вы кончили тем, что убили этого благородного человека и довели его жену до самоубийства.',\n",
       " 'Показания обеих женщин были в высшей степени точны.',\n",
       " '— Она была найдена тяжело раненной возле своего мертвого мужа.',\n",
       " 'Окно было закрыто на задвижку изнутри, обе женщины утверждали это с полной уверенностью.',\n",
       " 'Мы не могли оставить ее, раненную, на полу.',\n",
       " 'Мистер Хилтон Кьюбитт убит выстрелом прямо в сердце.',\n",
       " 'Если же вы думаете, что я в состоянии ранить ту женщину, значит, вы не знаете ни ее, ни меня. Ни один мужчина никогда не любил ни одной женщины так, как я любил ее.',\n",
       " 'Холме шарил в траве и листьях, как охотничий пес, разыскивающий раненую птицу.',\n",
       " 'Затем, с помощью конюха и работающего на конюшне мальчишки, они отнесли свою раненую хозяйку в ее комнату.',\n",
       " '— Я стрелял в него, но и он стрелял в меня, — следовательно, это нельзя назвать убийством.',\n",
       " '— Отвратительное состояние — чувствовать, что ты со всех сторон окружен какими-то неизвестными, невидимыми людьми, которые пытаются вовлечь тебя в какую-то беду, но еще нестерпимее видеть при этом, как изо дня в день постепенно убивают твою жену!',\n",
       " '«ИЛСИ, ГОТОВЬСЯ К СМЕРТИ»!',\n",
       " '— Вы совершенно правы, сэр: значит, был третий выстрел и, следовательно, был третий человек.',\n",
       " 'Она выстрелила сначала в него, потом в себя.',\n",
       " 'Я не могу оставить жену на ночь в одиночестве.',\n",
       " 'Вам, вероятно, кажется странным, мистер Холмс, что человек хорошего старинного рода вступает в брак с женщиной, ничего не зная о ее прошлом и о ее семье.',\n",
       " 'Она смертельно перепугалась. Она ничего не говорит мне, но я вижу в глазах у нее ужас.',\n",
       " 'Он умер мгновенно и безболезненно.',\n",
       " 'Я увидел, как из-за угла выползла темная согнутая фигура и уселась перед дверью. Схватив револьвер, я рванулся вперед, но жена судорожно обняла меня и удержала на месте. Я пытался оттолкнуть ее, но она вцепилась в меня еще отчаяннее.',\n",
       " 'Доктор удалился к своим пациентам.',\n",
       " '— Если Илей умрет, мне все равно, что будет со мною, — сказал американец.',\n",
       " 'Моя жена получила письмо из Америки — на конверте была американская марка. Жена смертельно побледнела, прочла письмо и швырнула в огонь.',\n",
       " 'Их хозяин лежал посреди комнаты лицом вниз. Он был мертв.',\n",
       " 'Возле окна корчилась его жена, прислонясь головой к стене. Рана ее была ужасна — кровь залила половину лица.',\n",
       " 'Так рассказывают служанки. Он умер, она при смерти.',\n",
       " 'Отвечая инспектору Мартину, обе женщины заявили, что все двери были заперты изнутри и что никому не удалось бы ускользнуть из дома. Отвечая Холмсу, они обе вспомнили, что почувствовали запах пороха, как только выбежали из своих комнат во втором этаже. — Советую вам обратить самое серьезное внимание на этот факт, — сказал Холме инспектору Мартину.',\n",
       " 'Если ты на мне женишься, Хилтон, ты женишься на женщине, которая сама ничего постыдного не совершила, но ты должен поверить мне на слово и позволить умолчать обо всем, что было со мною до того, как я стала твоей. Если это условие кажется тебе слишком тяжелым, возвращайся в Норфолк и предоставь мне продолжать ту одинокую жизнь, которую я вела до встречи с тобой».']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks.get_texts_for_search_results(ranked_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mirage.inference.prompters.APILLM import LLM\n",
    "llm = LLM()\n",
    "llm.do_request(query=query,\n",
    "               chunk_storage=chunks,\n",
    "               indexes=[element.chunk_storage_key for element in ranked_answer],\n",
    "               prompt='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
