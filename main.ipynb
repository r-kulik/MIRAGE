{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a Jupyter Notebook cell\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\Диплом\\MIRAGE\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "print(np.__version__)\n",
    "from mirage import WordCountingChunkingAlgorithm, FolderRawStorage, WhooshChunkStorage\n",
    "from mirage import HuggingFaceEmbedder, TextNormalizer\n",
    "from mirage import NatashaSentenceChunking, SemanticChunking\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = HuggingFaceEmbedder(model_name='BAAI/bge-m3', normalizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "\n",
    "documents = FolderRawStorage('data_test')\n",
    " # тут заменить на нужную папку\n",
    "chunks = WhooshChunkStorage(scoring_function=\"BM25F\", normalizer=True)\n",
    "# algorithm = WordCountingChunkingAlgorithm(documents, chunks, words_amount=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting text into the sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "442it [00:00, 26173.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating embeddings of the sentences for semantic grouping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [01:42<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding chunks to the storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [00:01<00:00, 98.80it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "algorithm = SemanticChunking(raw_storage=documents, chunk_storage=chunks, embedder=embedder, threshold=0.5, max_chunk_size=1000)\n",
    "algorithm.execute(visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.5 Conclusion 19\\n2.5 Conclusion\\nThese works, including the notable \"Think Before You Speak\" [19] paper,\\nhave introduced methods such as pause tokens to address computational ineffi-\\nciencies. These studies have laid a foundation by showing that allowing models\\nto ’pause’ can enhance their processing capabilities. Building on these foundations, this thesis introduces a method that advances\\nthe concept of pause tokens by eliminating the need for fine-tuning and changing\\nthe way of detection of the need to pause. Unlike the methods shown in the\\nexisting works, which typically require model retraining or changing the way\\nit’s prompted, this research proposes an on-the-fly inference-time mechanic that\\nidentifies complex areas of the text in real time. When such an area is detected,\\nthe model is forced to pause for multiple steps, iteratively refining its next output. Duringthesepauses,themodel’stemperatureislowered,sharpeningitsfocusand\\nincreasing the certainty of its outputs.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "index = chunks.get_indexes()[random.randint(1, 50)]\n",
    "print(len(chunks[index]))\n",
    "chunks[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ChunkStorage to VectorIndex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192/192 [01:08<00:00,  2.79it/s]\n"
     ]
    }
   ],
   "source": [
    "from mirage.index.vector_index.ram_vector_index import L2RAMVectorIndex\n",
    "from mirage import FaissIndexFlatL2, FaissIndexIVFPQR\n",
    "vector_index = L2RAMVectorIndex(dimensionality=embedder.get_dimensionality())\n",
    "embedder.convert_chunks_to_vector_index(chunks, vector_index, visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for QueryResult\nscore\n  Field required [type=missing, input_value={'distance': 0.42413747, ...4ef1-a79c-a3951cd8d9af'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m query_vector = embedder.embed(text=query)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# print(query_vector)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m vector_answer = \u001b[43mvector_index\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(vector_answer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\Диплом\\MIRAGE\\mirage\\index\\vector_index\\ram_vector_index\\L2RAMVectorIndex.py:115\u001b[39m, in \u001b[36mL2RAMVectorIndex.query\u001b[39m\u001b[34m(self, query_vector, top_k)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mquery\u001b[39m(\u001b[38;5;28mself\u001b[39m, query_vector: np.ndarray, top_k = \u001b[32m5\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[QueryResult]:\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\n\u001b[32m    114\u001b[39m         [\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m             \u001b[43mQueryResult\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# distance = np.sqrt(np.sum((query_vector - vkp.vector) ** 2)),\u001b[39;49;00m\n\u001b[32m    117\u001b[39m \u001b[43m                \u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_vector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvkp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_vector\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvkp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m                \u001b[49m\u001b[43mvector\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvkp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m                \u001b[49m\u001b[43mchunk_storage_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvkp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchunk_storage_key\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m vkp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.vector_pairs\n\u001b[32m    122\u001b[39m         ],\n\u001b[32m    123\u001b[39m         key=\u001b[38;5;28;01mlambda\u001b[39;00m x: -\u001b[32m1\u001b[39m * x.distance\n\u001b[32m    124\u001b[39m     )[  :\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.vector_pairs),  top_k)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\Диплом\\MIRAGE\\env\\Lib\\site-packages\\pydantic\\main.py:214\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    213\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    216\u001b[39m     warnings.warn(\n\u001b[32m    217\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    218\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    219\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    220\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    221\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for QueryResult\nscore\n  Field required [type=missing, input_value={'distance': 0.42413747, ...4ef1-a79c-a3951cd8d9af'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing"
     ]
    }
   ],
   "source": [
    "query = 'What is LLM'\n",
    "query_vector = embedder.embed(text=query)\n",
    "# print(query_vector)\n",
    "vector_answer = vector_index.query(\n",
    "    query_vector, top_k=5\n",
    ")\n",
    "print(vector_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\i'\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17524\\3838183163.py:6: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  path_to_model='mirage\\inference\\quorums\\model.bin',\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17524\\3838183163.py:6: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  path_to_model='mirage\\inference\\quorums\\model.bin',\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'mirage\\\\inference\\\\quorums\\\\model.bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmirage\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minference\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquorums\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mRusVectoresQuorum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RusVectoresQuorum\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m quorum = \u001b[43mRusVectoresQuorum\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunk_storage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_to_model\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmirage\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43minference\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mquorums\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mmodel.bin\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mPOS_thresholds\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mADJ\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mVERB\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.65\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_combinations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m fulltext_search_answer = quorum.query(query)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\Диплом\\MIRAGE\\mirage\\inference\\quorums\\RusVectoresQuorum.py:76\u001b[39m, in \u001b[36mRusVectoresQuorum.__init__\u001b[39m\u001b[34m(self, chunk_storage, path_to_model, global_similarity_threshold, second_closest_strategy, POS_thresholds, max_entries, max_combinations, max_synonims, visualize)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28mself\u001b[39m.morph = pymorphy3.MorphAnalyzer()\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# ------------ loading the Word2Vec Model from the file\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28mself\u001b[39m.word_vectors: KeyedVectors = \u001b[43mKeyedVectors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.visualize: \n\u001b[32m     79\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mAmount of vectors loaded in quorum: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.word_vectors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\Диплом\\MIRAGE\\env\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:1719\u001b[39m, in \u001b[36mKeyedVectors.load_word2vec_format\u001b[39m\u001b[34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[39m\n\u001b[32m   1672\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m   1673\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_word2vec_format\u001b[39m(\n\u001b[32m   1674\u001b[39m         \u001b[38;5;28mcls\u001b[39m, fname, fvocab=\u001b[38;5;28;01mNone\u001b[39;00m, binary=\u001b[38;5;28;01mFalse\u001b[39;00m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf8\u001b[39m\u001b[33m'\u001b[39m, unicode_errors=\u001b[33m'\u001b[39m\u001b[33mstrict\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   1675\u001b[39m         limit=\u001b[38;5;28;01mNone\u001b[39;00m, datatype=REAL, no_header=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1676\u001b[39m     ):\n\u001b[32m   1677\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[32m   1678\u001b[39m \n\u001b[32m   1679\u001b[39m \u001b[33;03m    Warnings\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1717\u001b[39m \n\u001b[32m   1718\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1720\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43municode_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43municode_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1721\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdatatype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_header\u001b[49m\u001b[43m=\u001b[49m\u001b[43mno_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1722\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\Диплом\\MIRAGE\\env\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:2048\u001b[39m, in \u001b[36m_load_word2vec_format\u001b[39m\u001b[34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[39m\n\u001b[32m   2045\u001b[39m             counts[word] = \u001b[38;5;28mint\u001b[39m(count)\n\u001b[32m   2047\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mloading projection weights from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, fname)\n\u001b[32m-> \u001b[39m\u001b[32m2048\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mutils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fin:\n\u001b[32m   2049\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m no_header:\n\u001b[32m   2050\u001b[39m         \u001b[38;5;66;03m# deduce both vocab_size & vector_size from 1st pass over file\u001b[39;00m\n\u001b[32m   2051\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m binary:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\Диплом\\MIRAGE\\env\\Lib\\site-packages\\smart_open\\smart_open_lib.py:177\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, compression, transport_params)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m transport_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    175\u001b[39m     transport_params = {}\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m fobj = \u001b[43m_shortcut_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    183\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fobj\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\Desktop\\Диплом\\MIRAGE\\env\\Lib\\site-packages\\smart_open\\smart_open_lib.py:375\u001b[39m, in \u001b[36m_shortcut_open\u001b[39m\u001b[34m(uri, mode, compression, buffering, encoding, errors, newline)\u001b[39m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mb\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m    373\u001b[39m     open_kwargs[\u001b[33m'\u001b[39m\u001b[33merrors\u001b[39m\u001b[33m'\u001b[39m] = errors\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_builtin_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mopen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'mirage\\\\inference\\\\quorums\\\\model.bin'"
     ]
    }
   ],
   "source": [
    "from mirage.inference.quorums.RusVectoresQuorum import RusVectoresQuorum\n",
    "\n",
    "\n",
    "quorum = RusVectoresQuorum(\n",
    "    chunk_storage=chunks, \n",
    "    path_to_model='mirage\\inference\\quorums\\model.bin',\n",
    "    POS_thresholds={\"ADJ\": 0.5, \"VERB\": 0.65},\n",
    "    visualize=True,\n",
    "    max_combinations=25)\n",
    "fulltext_search_answer = quorum.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fulltext_search_answer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmirage\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minference\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrerankers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mLinearCombinationReranker\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearCombinationReranker\n\u001b[32m      3\u001b[39m rank_fusion = LinearCombinationReranker(fulltext_score_weight=\u001b[32m0.25\u001b[39m, vector_score_weight=\u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m ranked_answer = rank_fusion(\u001b[43mfulltext_search_answer\u001b[49m, vector_answer)\n",
      "\u001b[31mNameError\u001b[39m: name 'fulltext_search_answer' is not defined"
     ]
    }
   ],
   "source": [
    "from mirage.inference.rerankers.LinearCombinationReranker import LinearCombinationReranker\n",
    "\n",
    "rank_fusion = LinearCombinationReranker(fulltext_score_weight=0.25, vector_score_weight=1)\n",
    "ranked_answer = rank_fusion(fulltext_search_answer, vector_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks.get_texts_for_search_results(ranked_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This text is about the theoretical framework and methodology of Large Language Models (LLMs) in natural language processing (NLP). It discusses the softmax function, temperature parameter, and its effect on the generated text, as well as the Transformer model and its self-attention system. Additionally, it touches on the topic of fine-tuning LLMs to follow specific instructions and proposes two mechanics to handle pause tokens.\n"
     ]
    }
   ],
   "source": [
    "from mirage.inference.prompters.APILLM import LLM\n",
    "from mirage.inference.prompters.LLMGroq import GroqLLM\n",
    "llm = GroqLLM()\n",
    "llm.do_request(query=\"What this text about?\",#query,\n",
    "               chunk_storage=chunks,\n",
    "            #    indexes=[element.chunk_storage_key for element in ranked_answer],\n",
    "               indexes=chunks.get_indexes()[9:12],\n",
    "               prompt_template=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
