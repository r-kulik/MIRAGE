{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\Диплом\\MIRAGE\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "print(np.__version__)\n",
    "\n",
    "from mirage import WordCountingChunkingAlgorithm, FolderRawStorage, WhooshChunkStorage\n",
    "from mirage import HuggingFaceEmbedder, TextNormalizer\n",
    "from mirage import NatashaSentenceChunking, SemanticChunking\n",
    "import os\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting text into the sentences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [00:00, 13996.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating embeddings of the sentences for semantic grouping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:10<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding chunks to the storage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 90.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting ChunkStorage to VectorIndex\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:08<00:00,  2.06it/s]\n"
     ]
    }
   ],
   "source": [
    "embedder = HuggingFaceEmbedder(model_name='BAAI/bge-m3', normalizer=True)\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "\n",
    "documents = FolderRawStorage('../data_test')\n",
    "chunks = WhooshChunkStorage(scoring_function=\"BM25F\", normalizer=True)\n",
    "# algorithm = WordCountingChunkingAlgorithm(documents, chunks, words_amount=100)\n",
    "\n",
    "\n",
    "algorithm = SemanticChunking(raw_storage=documents, chunk_storage=chunks, embedder=embedder, threshold=0.5, max_chunk_size=1000)\n",
    "algorithm.execute(visualize=True)\n",
    "\n",
    "from mirage.index.vector_index.ram_vector_index import L2RAMVectorIndex\n",
    "from mirage import FaissIndexFlatL2, FaissIndexIVFPQR\n",
    "vector_index = FaissIndexFlatL2(dimensionality=embedder.get_dimensionality())\n",
    "embedder.convert_chunks_to_vector_index(chunks, vector_index, visualize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Benchmark number: 0\n",
      "ap: 0.8333333333333333\n",
      "erp: 0.359336017285326\n",
      "ndcg: 0.9197207891481876\n",
      "--------------------\n",
      "Benchmark number: 1\n",
      "ap: 1.0\n",
      "erp: 0.46538892508553426\n",
      "ndcg: 1.0\n",
      "--------------------\n",
      "Benchmark number: 2\n",
      "ap: 1.0\n",
      "erp: 0.46020393390890024\n",
      "ndcg: 1.0\n",
      "--------------------\n",
      "Benchmark number: 3\n",
      "ap: 0.0\n",
      "erp: 0.19588061106658472\n",
      "ndcg: 0.0\n",
      "--------------------\n",
      "Benchmark number: 4\n",
      "ap: 1.0\n",
      "erp: 0.35755315246070896\n",
      "ndcg: 1.0\n",
      "--------------------\n",
      "Benchmark number: 5\n",
      "ap: 0.5\n",
      "erp: 0.19656266468092845\n",
      "ndcg: 0.6309297535714575\n",
      "--------------------\n",
      "Benchmark number: 6\n",
      "ap: 0.5\n",
      "erp: 0.2505108647878942\n",
      "ndcg: 0.6309297535714575\n",
      "--------------------\n",
      "Benchmark number: 7\n",
      "ap: 0.25\n",
      "erp: 0.2496457610980466\n",
      "ndcg: 0.43067655807339306\n",
      "--------------------\n",
      "Benchmark number: 8\n",
      "ap: 0.3666666666666667\n",
      "erp: 0.32351703043500274\n",
      "ndcg: 0.5437713091520254\n",
      "--------------------\n",
      "Benchmark number: 9\n",
      "ap: 1.0\n",
      "erp: 0.5097234677658711\n",
      "ndcg: 1.0\n",
      "--------------------\n",
      "Benchmark number: 10\n",
      "ap: 0.95\n",
      "erp: 0.39978202455812234\n",
      "ndcg: 0.9828920819566879\n",
      "--------------------\n",
      "Benchmark number: 11\n",
      "ap: 0.8875\n",
      "erp: 0.5066829375691633\n",
      "ndcg: 0.9558295932317544\n",
      "--------------------\n",
      "Benchmark number: 12\n",
      "ap: 0.0\n",
      "erp: 0.22873312661020348\n",
      "ndcg: 0.0\n",
      "--------------------\n",
      "Benchmark number: 13\n",
      "ap: 0.8333333333333333\n",
      "erp: 0.3598033149938589\n",
      "ndcg: 0.9197207891481876\n",
      "--------------------\n",
      "Benchmark number: 14\n",
      "ap: 1.0\n",
      "erp: 0.5550779568954685\n",
      "ndcg: 1.0\n",
      "--------------------\n",
      "Benchmark number: 15\n",
      "ap: 0.45\n",
      "erp: 0.3462135159235225\n",
      "ndcg: 0.6240505200038379\n",
      "--------------------\n",
      "Benchmark number: 16\n",
      "ap: 0.25\n",
      "erp: 0.2621540404040404\n",
      "ndcg: 0.43067655807339306\n",
      "--------------------\n",
      "Benchmark number: 17\n",
      "ap: 0.25\n",
      "erp: 0.2581470236840256\n",
      "ndcg: 0.43067655807339306\n",
      "--------------------\n",
      "Benchmark number: 18\n",
      "ap: 1.0\n",
      "erp: 0.5504349212803401\n",
      "ndcg: 1.0\n",
      "--------------------\n",
      "Benchmark number: 19\n",
      "ap: 0.3666666666666667\n",
      "erp: 0.32098221927019654\n",
      "ndcg: 0.5437713091520254\n",
      "--------------------\n",
      "Benchmark number: 20\n",
      "ap: 0.7555555555555555\n",
      "erp: 0.37060176979531817\n",
      "ndcg: 0.8854598815714874\n",
      "--------------------\n",
      "Benchmark number: 21\n",
      "ap: 1.0\n",
      "erp: 0.47162488441751116\n",
      "ndcg: 1.0\n",
      "--------------------\n",
      "Benchmark number: 22\n",
      "ap: 1.0\n",
      "erp: 0.5265219522432016\n",
      "ndcg: 1.0\n",
      "--------------------\n",
      "Benchmark number: 23\n",
      "ap: 0.9166666666666666\n",
      "erp: 0.46617511357487595\n",
      "ndcg: 0.9674679834891693\n",
      "--------------------\n",
      "Benchmark number: 24\n",
      "ap: 0.2\n",
      "erp: 0.23655404455689086\n",
      "ndcg: 0.38685280723454163\n"
     ]
    }
   ],
   "source": [
    "from RelFunc import *\n",
    "from RankMetr import RankMetr\n",
    "\n",
    "    \n",
    "    \n",
    "class Benchmark:\n",
    "    def __init__(self, querinator, embedenator, RelFunc: RelevanceFunction, rank_metr: RankMetr, top_k=5, bench_path: os.PathLike = '../benchmark/QnA/'):\n",
    "        self.querinator = querinator\n",
    "        self.embedenator = embedenator\n",
    "        self.benchmarks = []\n",
    "        self._get_benchmark(bench_path)\n",
    "        self.top_k = top_k\n",
    "        self.RF = RelFunc\n",
    "        self.RF.set_embedder(embedenator)\n",
    "        self.rank_metr = rank_metr  # Store the rank_metr instance\n",
    "    \n",
    "    def _get_benchmark(self, path):\n",
    "        for p in os.listdir(path):\n",
    "            with open(path+p, 'r', encoding='utf-8') as bench:\n",
    "                self.benchmarks.append(json.load(bench))\n",
    "                \n",
    "    def run_benchmark(self):\n",
    "        for bench_num, b in enumerate(self.benchmarks):\n",
    "            \n",
    "            chunk_real = b['ideal_context']        \n",
    "            self.RF.set_ideal_context(chunk_real)\n",
    "                \n",
    "            chunk_model = self.get_chunks(b['question'])\n",
    "            \n",
    "            rel_array = []\n",
    "            for i in range(self.top_k):\n",
    "                rel_array.append(self.RF.get_relevance(chunk_model[i]))\n",
    "            \n",
    "            print('-'*20)\n",
    "            print(f'Benchmark number: {bench_num}')\n",
    "            for func_name in dir(self.rank_metr):  # Use dir to get all attributes of rank_metr\n",
    "                if func_name.startswith('_'):  # Skip private methods\n",
    "                    continue\n",
    "                func = getattr(self.rank_metr, func_name)\n",
    "                if callable(func):  # Check if the attribute is a callable method\n",
    "                    print(f'{func_name}: {func(rel_array)}')\n",
    "    \n",
    "    def get_chunks(self, query: str):\n",
    "        query_vector = self.embedenator.embed(text=query)\n",
    "        answer = self.querinator.query(query_vector, top_k=self.top_k)\n",
    "        return [chunks[element.chunk_storage_key] for element in answer]\n",
    "    \n",
    " \n",
    "bench = Benchmark(querinator=vector_index,\n",
    "                  embedenator=embedder,\n",
    "                  RelFunc=IoU(0.2),\n",
    "                  rank_metr=RankMetr(),\n",
    "                  top_k=5)\n",
    "bench.run_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
